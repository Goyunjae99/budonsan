# 네이버 부동산 매물 크롤러 GUI 프로그램 PRD

## 1. 프로젝트 개요

### 1.1 프로젝트명
네이버 부동산 매물 정보 수집 및 관리 GUI 프로그램

### 1.2 프로젝트 목적
서울시 용산구 한강로3가 센트럴파크 단지의 모든 매물 정보를 자동으로 수집하고, 사용자 친화적인 GUI를 통해 조회 및 엑셀 파일로 저장할 수 있는 프로그램 개발

### 1.3 대상 사용자
- 부동산 중개업자
- 부동산 투자자
- 부동산 정보 수집이 필요한 일반 사용자

---

## 2. 기능 요구사항

### 2.1 핵심 기능

#### 2.1.1 매물 정보 수집 기능
- **기능 설명**: 네이버 부동산 웹사이트에서 센트럴파크 단지의 매물 정보를 자동으로 수집
- **수집 항목**:
  - 동 (예: 101동, 1동)
  - 가격 (예: 12억 5,000만원)
  - 면적 (예: 84.95㎡, 25.7평)
  - 층수 (예: 15/30층)
- **특수 처리**:
  - '저/중/고'로 표시된 매물은 상세 페이지를 클릭하여 정확한 층수 정보 추출
  - 네이버 차단 방지를 위한 랜덤 대기 시간 적용

#### 2.1.2 실시간 진행 상황 표시
- **기능 설명**: 크롤링 진행 상황을 실시간으로 표시
- **표시 정보**:
  - 현재 처리 중인 매물 번호 / 전체 매물 수
  - 진행률 (퍼센트)
  - 진행 상태 바 (Progress Bar)
  - 현재 수집 중인 매물의 동, 가격 정보
  - 로그 메시지 (성공/실패/오류)

#### 2.1.3 데이터 조회 및 표시 기능
- **기능 설명**: 수집된 매물 정보를 테이블 형태로 표시
- **표시 형식**:
  - 테이블 뷰 (QTableWidget 또는 QTableView)
  - 컬럼: 동, 가격, 면적, 층수
  - 정렬 기능 (각 컬럼 클릭 시 정렬)
  - 필터 기능 (검색어 입력 시 필터링)

#### 2.1.4 엑셀 파일 저장 기능
- **기능 설명**: 수집된 데이터를 엑셀 파일(.xlsx)로 저장
- **기능 세부사항**:
  - 파일 저장 대화상자 (QFileDialog)
  - 파일명 기본값: "센트럴파크_매물정보_YYYYMMDD_HHMMSS.xlsx"
  - 저장 성공/실패 메시지 표시
  - 엑셀 파일 형식:
    - 헤더 행 (동, 가격, 면적, 층수)
    - 데이터 행
    - 컬럼 너비 자동 조정
    - 한글 인코딩 지원

#### 2.1.5 크롤링 제어 기능
- **기능 설명**: 크롤링 시작, 일시정지, 중지 기능
- **버튼**:
  - 시작 버튼: 크롤링 시작
  - 일시정지 버튼: 크롤링 일시 정지 (선택사항)
  - 중지 버튼: 크롤링 강제 중지

### 2.2 부가 기능

#### 2.2.1 설정 기능
- **대기 시간 설정**: 최소/최대 대기 시간 조정 (기본값: 1.0~3.0초)
- **헤드리스 모드**: 브라우저 표시 여부 설정
- **자동 저장**: 크롤링 완료 시 자동으로 엑셀 파일 저장 여부

#### 2.2.2 통계 정보 표시
- **기능 설명**: 수집된 데이터의 통계 정보 표시
- **표시 항목**:
  - 전체 매물 수
  - 가격 범위 (최저가, 최고가, 평균가)
  - 면적 범위
  - 동별 매물 수

#### 2.2.3 데이터 내보내기
- CSV 파일로 저장 (기존 기능 유지)
- 엑셀 파일로 저장 (신규 기능)

---

## 3. UI/UX 요구사항

### 3.1 화면 구성

#### 3.1.1 메인 윈도우 레이아웃
```
┌─────────────────────────────────────────────────────────┐
│  네이버 부동산 매물 크롤러                              │
├─────────────────────────────────────────────────────────┤
│  [단지 정보]                                            │
│  지역: 서울시 용산구 한강로3가 센트럴파크               │
│  URL: [입력 필드] [크롤링 시작] [중지]                  │
├─────────────────────────────────────────────────────────┤
│  [진행 상황]                                            │
│  진행률: [████████░░░░░░░░░░] 50%                      │
│  현재: 매물 5/10 처리 중...                             │
│  로그: [스크롤 가능한 텍스트 영역]                      │
├─────────────────────────────────────────────────────────┤
│  [매물 정보 테이블]                                     │
│  ┌──────┬──────────┬──────────┬────────┐              │
│  │ 동   │ 가격     │ 면적     │ 층수   │              │
│  ├──────┼──────────┼──────────┼────────┤              │
│  │ 101동│ 12억...  │ 84.95㎡  │ 15/30층│              │
│  └──────┴──────────┴──────────┴────────┘              │
├─────────────────────────────────────────────────────────┤
│  [통계 정보]                                            │
│  전체 매물: 10개 | 최저가: 8억 | 최고가: 15억          │
├─────────────────────────────────────────────────────────┤
│  [엑셀 저장] [CSV 저장] [설정]                          │
└─────────────────────────────────────────────────────────┘
```

#### 3.1.2 주요 UI 컴포넌트

**상단 영역**
- 제목: "네이버 부동산 매물 크롤러"
- 단지 정보 표시 영역
- URL 입력 필드 (기본값: 센트럴파크 URL)
- 크롤링 제어 버튼 (시작/중지)

**진행 상황 영역**
- 진행률 프로그레스 바
- 현재 상태 텍스트
- 로그 텍스트 영역 (스크롤 가능, 최대 100줄)

**매물 정보 테이블**
- QTableWidget 사용
- 컬럼: 동, 가격, 면적, 층수
- 행 선택 가능
- 컬럼 헤더 클릭 시 정렬
- 검색/필터 기능 (선택사항)

**하단 영역**
- 통계 정보 표시
- 저장 버튼 (엑셀, CSV)
- 설정 버튼

### 3.2 디자인 요구사항

#### 3.2.1 색상
- 기본 테마: 밝은 배경, 어두운 텍스트
- 진행 중: 파란색 계열
- 완료: 초록색 계열
- 오류: 빨간색 계열

#### 3.2.2 폰트
- 기본 폰트: 시스템 기본 폰트 (맑은 고딕, 나눔고딕 등)
- 제목: 14pt, Bold
- 본문: 10pt, Regular
- 테이블: 9pt, Regular

#### 3.2.3 레이아웃
- 반응형 레이아웃 (윈도우 크기 조정 시 자동 조정)
- 최소 윈도우 크기: 800x600
- 적절한 여백 및 패딩

### 3.3 사용자 경험 (UX)

#### 3.3.1 피드백
- 모든 버튼 클릭 시 즉각적인 피드백
- 크롤링 진행 중 버튼 비활성화
- 완료/오류 시 알림 메시지 표시

#### 3.3.2 오류 처리
- 네트워크 오류 시 재시도 옵션 제공
- 페이지 로딩 실패 시 명확한 오류 메시지
- 예외 상황 처리 및 사용자 안내

---

## 4. 기술 스택

### 4.1 개발 언어 및 프레임워크
- **Python**: 3.8 이상
- **PySide6**: GUI 프레임워크
- **Playwright**: 웹 크롤링 라이브러리
- **pandas**: 데이터 처리 및 엑셀 저장
- **openpyxl**: 엑셀 파일 생성/편집

### 4.2 주요 라이브러리
```
playwright==1.40.0
PySide6>=6.5.0
pandas>=2.0.0
openpyxl>=3.1.0
```

### 4.3 아키텍처

#### 4.3.1 모듈 구조
```
naver_estate_gui/
├── main.py                 # 프로그램 진입점
├── gui/
│   ├── main_window.py      # 메인 윈도우 클래스
│   ├── crawler_thread.py   # 크롤링 스레드 클래스
│   └── widgets.py          # 커스텀 위젯
├── crawler/
│   └── naver_crawler.py    # 크롤러 로직 (기존 코드 리팩토링)
├── utils/
│   ├── excel_exporter.py   # 엑셀 저장 기능
│   └── data_processor.py  # 데이터 처리 유틸리티
└── config/
    └── settings.py          # 설정 관리
```

#### 4.3.2 비동기 처리
- 크롤링 작업은 별도 스레드(QThread)에서 실행
- GUI 스레드 블로킹 방지
- 시그널/슬롯을 통한 스레드 간 통신

---

## 5. 데이터 구조

### 5.1 매물 정보 데이터 구조
```python
{
    '동': str,      # 예: "101동", "1동"
    '가격': str,    # 예: "12억 5,000만원"
    '면적': str,    # 예: "84.95㎡", "25.7평"
    '층수': str     # 예: "15/30층"
}
```

### 5.2 엑셀 파일 구조
- **시트명**: "매물정보"
- **헤더 행**: 1행 (동, 가격, 면적, 층수)
- **데이터 행**: 2행부터
- **형식**: 
  - 텍스트 정렬: 왼쪽 정렬
  - 숫자 형식: 텍스트로 저장 (가격, 면적)
  - 컬럼 너비: 자동 조정

---

## 6. 사용자 시나리오

### 6.1 기본 크롤링 시나리오
1. 사용자가 프로그램 실행
2. URL 입력 필드에 센트럴파크 URL이 기본값으로 표시됨
3. 사용자가 "크롤링 시작" 버튼 클릭
4. 프로그램이 네이버 부동산 페이지에 접속
5. 매물 목록을 찾아 각 매물 정보 수집
6. '저/중/고' 매물은 상세 페이지 클릭하여 층수 정보 추출
7. 진행 상황이 실시간으로 업데이트됨
8. 수집된 데이터가 테이블에 표시됨
9. 크롤링 완료 시 완료 메시지 표시
10. 사용자가 "엑셀 저장" 버튼 클릭
11. 파일 저장 대화상자에서 저장 위치 선택
12. 엑셀 파일로 저장 완료

### 6.2 오류 처리 시나리오
1. 네트워크 연결 실패 시 오류 메시지 표시
2. 페이지 로딩 실패 시 재시도 옵션 제공
3. 특정 매물 정보 추출 실패 시 로그에 기록하고 다음 매물 계속 처리

### 6.3 중지 시나리오
1. 사용자가 크롤링 중 "중지" 버튼 클릭
2. 현재 처리 중인 매물 완료 후 안전하게 중지
3. 이미 수집된 데이터는 유지됨

---

## 7. 비기능 요구사항

### 7.1 성능
- 크롤링 속도: 매물당 평균 2-3초 (랜덤 대기 시간 포함)
- GUI 반응성: 크롤링 중에도 UI 반응 유지
- 메모리 사용: 500MB 이하

### 7.2 안정성
- 네트워크 오류 시 재시도 메커니즘
- 예외 상황 처리 및 로깅
- 크롤링 중 프로그램 종료 시 안전하게 종료

### 7.3 사용성
- 직관적인 UI/UX
- 명확한 상태 표시
- 오류 메시지의 명확성

### 7.4 호환성
- Windows 10 이상 지원
- Python 3.8 이상 지원

---

## 8. 제약사항 및 고려사항

### 8.1 법적/윤리적 고려사항
- 네이버 부동산 이용약관 준수
- robots.txt 확인 및 준수
- 과도한 요청으로 인한 IP 차단 방지 (랜덤 대기 시간 적용)
- 수집된 데이터의 사용 목적 명시

### 8.2 기술적 제약사항
- 네이버 부동산 웹사이트 구조 변경 시 코드 수정 필요
- JavaScript 렌더링이 필요한 경우 Playwright 사용
- 네트워크 상태에 따른 크롤링 성공률 변동

### 8.3 유지보수
- 네이버 부동산 HTML 구조 변경 시 선택자 업데이트 필요
- 로깅 기능을 통한 디버깅 용이성 확보
- 설정 파일을 통한 유연한 설정 관리

---

## 9. 개발 단계

### 9.1 Phase 1: 기본 기능 구현
- GUI 기본 레이아웃 구성
- 크롤러 스레드 구현
- 기본 크롤링 기능 통합

### 9.2 Phase 2: 데이터 표시 및 저장
- 테이블 뷰 구현
- 엑셀 저장 기능 구현
- 진행 상황 표시 구현

### 9.3 Phase 3: 부가 기능 및 개선
- 통계 정보 표시
- 설정 기능
- 오류 처리 개선
- UI/UX 개선

### 9.4 Phase 4: 테스트 및 최적화
- 단위 테스트
- 통합 테스트
- 성능 최적화
- 사용자 테스트

---

## 10. 성공 기준

### 10.1 기능적 성공 기준
- 센트럴파크 단지의 모든 매물 정보 수집 성공
- '저/중/고' 매물의 정확한 층수 정보 추출 성공
- 엑셀 파일로 정상 저장 및 열기 가능

### 10.2 사용성 성공 기준
- 사용자가 별도 학습 없이 프로그램 사용 가능
- 크롤링 진행 상황을 명확하게 파악 가능
- 오류 발생 시 명확한 안내 메시지 제공

### 10.3 안정성 성공 기준
- 네트워크 오류 시에도 안정적으로 동작
- 크롤링 중 프로그램 크래시 없음
- 대량의 매물 처리 시에도 안정적 동작

---

## 11. 향후 개선 사항

### 11.1 기능 확장
- 여러 단지 동시 크롤링 지원
- 크롤링 스케줄링 기능
- 데이터베이스 저장 기능
- 차트/그래프를 통한 데이터 시각화

### 11.2 사용성 개선
- 다크 모드 지원
- 다국어 지원
- 사용자 가이드/도움말 기능

### 11.3 성능 개선
- 병렬 크롤링 지원
- 캐싱 기능
- 증분 업데이트 기능

---

## 12. 참고 자료

### 12.1 관련 문서
- 기존 크롤러 코드: `naver_estate_crawler.py`
- 네이버 부동산 URL: `https://new.land.naver.com/complexes/117804`

### 12.2 기술 문서
- PySide6 공식 문서: https://doc.qt.io/qtforpython/
- Playwright Python 문서: https://playwright.dev/python/
- pandas 문서: https://pandas.pydata.org/docs/

---

**문서 버전**: 1.0  
**작성일**: 2026-02-09  
**최종 수정일**: 2026-02-09
